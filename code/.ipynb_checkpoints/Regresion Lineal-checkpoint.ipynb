{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#(a)\n",
    "url = 'http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep='\\t', header=0)\n",
    "\n",
    "# Drop: devuelve un nuevo objeto con las etiquetas y ejes dados removidos\n",
    "# Con drop se elimina columna sin nombre que denota la posicion de cada registro del dataframe\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# la columna train indica si el registro pertenece o no al conjunto de entrenamiento. Almacenamos esta info en istrain_str\n",
    "istrain_str = df['train']\n",
    "istrain = np.asarray([True if s == 'T' else False for s in istrain_str])\n",
    "istest = np.logical_not(istrain)\n",
    "\n",
    "#Se elimina la etiqueta train y columna asociada a esta con la función drop.\n",
    "df = df.drop('train', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 9)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 9 columns):\n",
      "lcavol     97 non-null float64\n",
      "lweight    97 non-null float64\n",
      "age        97 non-null int64\n",
      "lbph       97 non-null float64\n",
      "svi        97 non-null int64\n",
      "lcp        97 non-null float64\n",
      "gleason    97 non-null int64\n",
      "pgg45      97 non-null int64\n",
      "lpsa       97 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 6.9 KB\n",
      "\n",
      "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
      "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
      "mean    1.350010   3.628943  63.865979   0.100356   0.216495  -0.179366   \n",
      "std     1.178625   0.428411   7.445117   1.450807   0.413995   1.398250   \n",
      "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
      "25%     0.512824   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
      "50%     1.446919   3.623007  65.000000   0.300105   0.000000  -0.798508   \n",
      "75%     2.127041   3.876396  68.000000   1.558145   0.000000   1.178655   \n",
      "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.904165   \n",
      "\n",
      "         gleason       pgg45       lpsa  \n",
      "count  97.000000   97.000000  97.000000  \n",
      "mean    6.752577   24.381443   2.478387  \n",
      "std     0.722134   28.204035   1.154329  \n",
      "min     6.000000    0.000000  -0.430783  \n",
      "25%     6.000000    0.000000   1.731656  \n",
      "50%     7.000000   15.000000   2.591516  \n",
      "75%     7.000000   40.000000   3.056357  \n",
      "max     9.000000  100.000000   5.582932  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(b)\n",
    "#97 filas 9 columnas\n",
    "print df.shape\n",
    "print \"\"\n",
    "df.info()\n",
    "print \"\"\n",
    "print df.describe()\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             lcavol       lweight           age          lbph           svi  \\\n",
      "count  9.700000e+01  9.700000e+01  9.700000e+01  9.700000e+01  9.700000e+01   \n",
      "mean  -9.614302e-17 -3.216213e-16  3.433679e-16 -4.721309e-17 -1.327689e-16   \n",
      "std    1.005195e+00  1.005195e+00  1.005195e+00  1.005195e+00  1.005195e+00   \n",
      "min   -2.300218e+00 -2.942386e+00 -3.087227e+00 -1.030029e+00 -5.256575e-01   \n",
      "25%   -7.139973e-01 -5.937689e-01 -5.219612e-01 -1.030029e+00 -5.256575e-01   \n",
      "50%    8.264956e-02 -1.392703e-02  1.531086e-01  1.383966e-01 -5.256575e-01   \n",
      "75%    6.626939e-01  5.806076e-01  5.581506e-01  1.010033e+00 -5.256575e-01   \n",
      "max    2.107397e+00  2.701661e+00  2.043304e+00  1.542252e+00  1.902379e+00   \n",
      "\n",
      "                lcp       gleason         pgg45       lpsa  \n",
      "count  9.700000e+01  9.700000e+01  9.700000e+01  97.000000  \n",
      "mean   8.240831e-17 -1.476482e-16 -1.816989e-16   2.478387  \n",
      "std    1.005195e+00  1.005195e+00  1.005195e+00   1.154329  \n",
      "min   -8.676552e-01 -1.047571e+00 -8.689573e-01  -0.430783  \n",
      "25%   -8.676552e-01 -1.047571e+00 -8.689573e-01   1.731656  \n",
      "50%   -4.450983e-01  3.444069e-01 -3.343557e-01   2.591516  \n",
      "75%    9.762744e-01  3.444069e-01  5.566470e-01   3.056357  \n",
      "max    2.216735e+00  3.128363e+00  2.695054e+00   5.582932  \n"
     ]
    }
   ],
   "source": [
    "#(c)\n",
    "#Normalizacion\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "#La variable Y (lPSA) no se normaliza, sólo se normalizan las caracteristicas/predictores (features)\n",
    "df_scaled['lpsa'] = df['lpsa']\n",
    "\n",
    "# Notamos que una vez normalizado, el promedio (mean) de cada feature es practicamente 0\n",
    "# y la desviacion estandar (std) es muy cercana a 1.\n",
    "print df_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(d)\n",
    "# Se crea el modelo de regresion lineal\n",
    "X = df_scaled.ix[:,:-1] # Se obtinen las Caracteristicas (features) lcavol...pgg45\n",
    "N = X.shape[0] # Cantidad de datos (97 filas/registros)\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N)) # Se agrega la columna Intercepto (columna de unos)\n",
    "y = df_scaled['lpsa'] # La variable dependiente lPSA es almancenada en y\n",
    "Xtrain = X[istrain] # Se crea el conjunto de entrenamiento para las caracteristicas\n",
    "ytrain = y[istrain] # Se crea el conjunto de entramiento para la variable a predecir\n",
    "Xtest = X[np.logical_not(istrain)] # Se crea el conjunto de prueba para las caracteristicas PSA\n",
    "ytest = y[np.logical_not(istrain)] # Se crea el conjunto de prueba para la variable a predecir PSA\n",
    "linreg = lm.LinearRegression(fit_intercept = False) #Generación del modelo\n",
    "linreg.fit(Xtrain, ytrain) # Se ajusta (fit) el modelo de acuerdo a los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(e)\n",
    "# Se obtiene el peso asociado a cada variable y su error estandar\n",
    "weights = linreg.coef_\n",
    "SEM = np.asarray(Xtrain.std()) / np.sqrt(len(Xtrain))\n",
    "# A partir de lo anterior, se calculan los Z-score de cada variable\n",
    "Z_score = weights / SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_test = 0.5096\n",
      "Cross validation\n",
      "k = 5  mse = 0.9565\n",
      "k = 10  mse = 0.7572\n"
     ]
    }
   ],
   "source": [
    "#(f)\n",
    "#Se estima error de prediccion del modelo utilizando k-fold k = 5 y k = 10\n",
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "print 'mse_test = %.4f'% mse_test\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "print 'Cross validation'\n",
    "for i in range(5,11,5):\n",
    "    k_fold = cross_validation.KFold(len(Xm),i)\n",
    "    mse_cv = 0\n",
    "    for k, (train, val) in enumerate(k_fold):\n",
    "      linreg = lm.LinearRegression(fit_intercept = False)\n",
    "      linreg.fit(Xm[train], ym[train])\n",
    "      yhat_val = linreg.predict(Xm[val])\n",
    "      mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "      mse_cv += mse_fold\n",
    "    mse_cv = mse_cv/i\n",
    "    print 'k = %d'% i, ' mse = %.4f'% mse_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se estima error de prediccion por cada dato de entrenamiento\n",
    "yhat_train = linreg.predict(Xtrain)\n",
    "ytrain_array = np.asarray(ytrain)\n",
    "error = yhat_train - ytrain_array\n",
    "\n",
    "#Se genera grafico de errores\n",
    "stats.probplot(error, dist='norm', plot=plt)\n",
    "plt.title('Siguen los errores de prediccion sobre el conjunto de entrenamiento una distribucion normal?')\n",
    "plt.ylabel('Error dato de entrenamiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
