{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Regresión Lineal Ordinaria (LSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Construcción del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep='\\t', header=0)\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "istrain_str = df['train']\n",
    "istrain = np.asarray([True if s == 'T' else False for s in istrain_str])\n",
    "istest = np.logical_not(istrain)\n",
    "df = df.drop('train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función drop devuelve un nuevo objeto con las etiquetas y ejes dados removidos.\n",
    "Entonces, se remueve la columna sin nombre que denota la posición de cada registro del _dataframe_, con el siguiente código:\n",
    "```python\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "```\n",
    "Además la columna _train_ indica si el registro pertenece o no al conjunto de entrenamiento. Una vez almacenada en la variable *istrain_str* se elimina del conjunto de datos con la función drop, ya que no es un predictor (característica).\n",
    "\n",
    "```python\n",
    "df = df.drop('train', axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Descripción del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset se compone de 97  registros (pacientes), cada uno de los cuáles está descrito por 9 variables.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 9 columns):\n",
      "lcavol     97 non-null float64\n",
      "lweight    97 non-null float64\n",
      "age        97 non-null int64\n",
      "lbph       97 non-null float64\n",
      "svi        97 non-null int64\n",
      "lcp        97 non-null float64\n",
      "gleason    97 non-null int64\n",
      "pgg45      97 non-null int64\n",
      "lpsa       97 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 6.9 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    1.350010   3.628943  63.865979   0.100356   0.216495  -0.179366   \n",
       "std     1.178625   0.428411   7.445117   1.450807   0.413995   1.398250   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.512824   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.446919   3.623007  65.000000   0.300105   0.000000  -0.798508   \n",
       "75%     2.127041   3.876396  68.000000   1.558145   0.000000   1.178655   \n",
       "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason       pgg45       lpsa  \n",
       "count  97.000000   97.000000  97.000000  \n",
       "mean    6.752577   24.381443   2.478387  \n",
       "std     0.722134   28.204035   1.154329  \n",
       "min     6.000000    0.000000  -0.430783  \n",
       "25%     6.000000    0.000000   1.731656  \n",
       "50%     7.000000   15.000000   2.591516  \n",
       "75%     7.000000   40.000000   3.056357  \n",
       "max     9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'El dataset se compone de %d'% df.shape[0],' registros (pacientes), cada uno de los cuáles está descrito por %d variables.\\n'% df.shape[1]\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables del conjunto de datos se describen a continuación:\n",
    "1. **lcavol**: Logaritmo del volumen de cáncer presente. (Predictor)\n",
    "3. **lweight**: Logaritmo del peso de la próstata. (Predictor)\n",
    "4. **age**: Edad. (Predictor)\n",
    "5. **lbph**: Logaritmo de la cantidad de hiperplasia benigna de próstata. (Predictor)\n",
    "6. **svi**: Indica si existe invasión de la vesícula seminal o no. (Predictor)\n",
    "7. **lcp**: Logaritmo de la penetración capsular. (Predictor)\n",
    "8. **gleason**: Medida del grado de agresividad del cáncer, en base a la escala de Gleason. (Predictor)\n",
    "9. **pgg45**: Porcentaje que representa la presencia de los patrones de Gleason 4 y 5. (Predictor)\n",
    "10. **lpsa**: Logaritmo del nivel de antígeno prostático específico (PSA). (Variable que se quiere predecir)\n",
    "\n",
    "Se debe resaltar que no existen valores nulos para ningún registro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-9.614302e-17</td>\n",
       "      <td>-3.216213e-16</td>\n",
       "      <td>3.433679e-16</td>\n",
       "      <td>-4.721309e-17</td>\n",
       "      <td>-1.327689e-16</td>\n",
       "      <td>8.240831e-17</td>\n",
       "      <td>-1.476482e-16</td>\n",
       "      <td>-1.816989e-16</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.005195e+00</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.300218e+00</td>\n",
       "      <td>-2.942386e+00</td>\n",
       "      <td>-3.087227e+00</td>\n",
       "      <td>-1.030029e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-8.676552e-01</td>\n",
       "      <td>-1.047571e+00</td>\n",
       "      <td>-8.689573e-01</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.139973e-01</td>\n",
       "      <td>-5.937689e-01</td>\n",
       "      <td>-5.219612e-01</td>\n",
       "      <td>-1.030029e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-8.676552e-01</td>\n",
       "      <td>-1.047571e+00</td>\n",
       "      <td>-8.689573e-01</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.264956e-02</td>\n",
       "      <td>-1.392703e-02</td>\n",
       "      <td>1.531086e-01</td>\n",
       "      <td>1.383966e-01</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>-4.450983e-01</td>\n",
       "      <td>3.444069e-01</td>\n",
       "      <td>-3.343557e-01</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.626939e-01</td>\n",
       "      <td>5.806076e-01</td>\n",
       "      <td>5.581506e-01</td>\n",
       "      <td>1.010033e+00</td>\n",
       "      <td>-5.256575e-01</td>\n",
       "      <td>9.762744e-01</td>\n",
       "      <td>3.444069e-01</td>\n",
       "      <td>5.566470e-01</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.107397e+00</td>\n",
       "      <td>2.701661e+00</td>\n",
       "      <td>2.043304e+00</td>\n",
       "      <td>1.542252e+00</td>\n",
       "      <td>1.902379e+00</td>\n",
       "      <td>2.216735e+00</td>\n",
       "      <td>3.128363e+00</td>\n",
       "      <td>2.695054e+00</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lcavol       lweight           age          lbph           svi  \\\n",
       "count  9.700000e+01  9.700000e+01  9.700000e+01  9.700000e+01  9.700000e+01   \n",
       "mean  -9.614302e-17 -3.216213e-16  3.433679e-16 -4.721309e-17 -1.327689e-16   \n",
       "std    1.005195e+00  1.005195e+00  1.005195e+00  1.005195e+00  1.005195e+00   \n",
       "min   -2.300218e+00 -2.942386e+00 -3.087227e+00 -1.030029e+00 -5.256575e-01   \n",
       "25%   -7.139973e-01 -5.937689e-01 -5.219612e-01 -1.030029e+00 -5.256575e-01   \n",
       "50%    8.264956e-02 -1.392703e-02  1.531086e-01  1.383966e-01 -5.256575e-01   \n",
       "75%    6.626939e-01  5.806076e-01  5.581506e-01  1.010033e+00 -5.256575e-01   \n",
       "max    2.107397e+00  2.701661e+00  2.043304e+00  1.542252e+00  1.902379e+00   \n",
       "\n",
       "                lcp       gleason         pgg45       lpsa  \n",
       "count  9.700000e+01  9.700000e+01  9.700000e+01  97.000000  \n",
       "mean   8.240831e-17 -1.476482e-16 -1.816989e-16   2.478387  \n",
       "std    1.005195e+00  1.005195e+00  1.005195e+00   1.154329  \n",
       "min   -8.676552e-01 -1.047571e+00 -8.689573e-01  -0.430783  \n",
       "25%   -8.676552e-01 -1.047571e+00 -8.689573e-01   1.731656  \n",
       "50%   -4.450983e-01  3.444069e-01 -3.343557e-01   2.591516  \n",
       "75%    9.762744e-01  3.444069e-01  5.566470e-01   3.056357  \n",
       "max    2.216735e+00  3.128363e+00  2.695054e+00   5.582932  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Normalizacion\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "#La variable Y (lPSA) no se normaliza, sólo se normalizan las caracteristicas/predictores (features)\n",
    "df_scaled['lpsa'] = df['lpsa']\n",
    "\n",
    "# Notamos que una vez normalizado, el promedio (mean) de cada feature es practicamente 0\n",
    "# y la desviacion estandar (std) es muy cercana a 1.\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importancia de Normalizar\n",
    "Antes generar un modelo predictivo es necesario normalizar los datos, pues se está trabajando con variables medidas en unidades y escalas diferentes. Al normalizar, se eliminan los efectos de la media y la varianza de cada variable, volviéndose posible realizar comparaciones razonables entre estas. Sólo se deben normalizar las características (_features_), por tanto la variable _lpsa_ se mantiene respecto al _dataset_ original. También, se observa que la media de cada variable tiende a 0 y la varianza es muy cercana a 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Regresión lineal ordinaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "# Se crea el modelo de regresion lineal\n",
    "X = df_scaled.ix[:,:-1] # Se obtinen las Caracteristicas (features) lcavol...pgg45\n",
    "N = X.shape[0] # Cantidad de datos (97 filas/registros)\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N)) # Se agrega la columna Intercepto (columna de unos)\n",
    "y = df_scaled['lpsa'] # La variable dependiente lPSA es almancenada en y\n",
    "Xtrain = X[istrain] # Se crea el conjunto de entrenamiento para las caracteristicas\n",
    "ytrain = y[istrain] # Se crea el conjunto de entramiento para la variable a predecir\n",
    "Xtest = X[np.logical_not(istrain)] # Se crea el conjunto de prueba para las caracteristicas PSA\n",
    "ytest = y[np.logical_not(istrain)] # Se crea el conjunto de prueba para la variable a predecir PSA\n",
    "linreg = lm.LinearRegression(fit_intercept = False) #Generación del modelo\n",
    "linreg.fit(Xtrain, ytrain) # Se ajusta (fit) el modelo de acuerdo a los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Pesos y Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     Peso       Z-score   \n",
      "lcavol       0.5966     4.5257\n",
      "lweight      0.2723     2.7353\n",
      "age         -0.1456    -1.3804\n",
      "lbph         0.1893     1.7785\n",
      "svi          0.1794     1.3942\n",
      "lcp         -0.1591    -0.9890\n",
      "gleason      0.1008     0.6665\n",
      "pgg45        0.1149     0.7183\n",
      "intercept     2.4001    25.6777\n"
     ]
    }
   ],
   "source": [
    "# Se obtiene el peso asociado a cada variable y su error estandar\n",
    "weights = linreg.coef_\n",
    "\n",
    "# Se estima la varianza \n",
    "yhat_train = linreg.predict(Xtrain)\n",
    "N = Xtrain.shape[0]\n",
    "p = Xtrain.shape[1]\n",
    "varianza = sum(np.power(yhat_train - ytrain, 2)) / (N - p - 1)\n",
    "\n",
    "# Se obtiene vj que es el elemnto jth de la diagonal de (X.T*X)^-1\n",
    "vj = np.diag(np.linalg.pinv(Xtrain.T.dot(Xtrain)))\n",
    "\n",
    "# A partir de lo anterior, se calculan los Z-score de cada variable\n",
    "Z_score = weights/( np.sqrt(varianza* vj))\n",
    "\n",
    "print '{:12} {:10} {:10}'.format('Variable', 'Peso', 'Z-score')\n",
    "for name, w, z in zip(Xtrain.columns.values, weights, Z_score):\n",
    "    print '{:8} {:10.4f} {:10.4f}'.format(name, w, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo al valor de *z_score*, las variables que presentan una mayor correlación con la variable a predecir son *lcavol*, *lweight* y *svi*. Si se utiliza un nivel de significancia del 5%, aquellas variables que se encuentren en el intervalo [-2.0, +2.0] no existirá suficiente evidencia que demuestre la relación con *lpsa*. Así, las variables *age*, *lbph*, *gleason* no están relacionadas con la variable a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Estimación de error de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE test sin Cross Validation = 0.5213\n",
      "Cross validation\n",
      "k = 5    MSE = 0.9565\n",
      "k = 10   MSE = 0.7572\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "#Se estima error de prediccion del modelo utilizando k-fold k = 5 y k = 10\n",
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "print 'MSE test sin Cross Validation = %.4f'% mse_test\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "print 'Cross validation'\n",
    "for i in range(5,11,5):\n",
    "    k_fold = cross_validation.KFold(len(Xm),i)\n",
    "    mse_cv = 0\n",
    "    for k, (train, val) in enumerate(k_fold):\n",
    "      linreg = lm.LinearRegression(fit_intercept = False)\n",
    "      linreg.fit(Xm[train], ym[train])\n",
    "      yhat_val = linreg.predict(Xm[val])\n",
    "      mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "      mse_cv += mse_fold\n",
    "    mse_cv = mse_cv/i\n",
    "    print 'k = %-3d'% i, ' MSE = %.4f'% mse_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el error cuadrático medio aumenta bastante al utilizar cross-validation en comparación al resultado obtenido sin usarlo. Esto indica que existe un alto nivel de dependencia del modelo respecto a los datos usados para construirlo. Es decir, el modelo se sobre ajusta (*overfitting*) a los datos de entrenamiento. Por otro lado, se debe tener en cuenta que el conjunto de datos es bastante pequeño, perjudicando al desempeño cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Quantile-Quantile plot (Q-Q plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEPCAYAAACzwehFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCSq/weUBhUJeMROvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb8bc278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Se estima error de prediccion por cada dato de entrenamiento\n",
    "yhat_train = linreg.predict(Xtrain)\n",
    "ytrain_array = np.asarray(ytrain)\n",
    "error = yhat_train - ytrain_array\n",
    "\n",
    "#Se genera grafico de errores\n",
    "stats.probplot(error, dist='norm', plot=plt)\n",
    "plt.title('')\n",
    "plt.ylabel('Error dato de entrenamiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ¿Existe normalidad en los datos?\n",
    "Se puede observar en el gráfico, que el conjunto de errores en los datos de entrenamiento comparados con los percentiles de una distribución normal pueden representarse mediante una recta. Esto se reafirmado con el coeficiente de correlación $R^2 = 0.9827$. Como consecuencia de lo anterior, y de acuerdo con el marco teórico, es correcto señalar que los errores siguen una distribución normal."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
