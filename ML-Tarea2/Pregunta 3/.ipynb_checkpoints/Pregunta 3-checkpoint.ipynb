{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) En primer lugar se genera la matriz dispersa leyendo el archivo de skill de los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def CrearSparse():\n",
    "    row, col, data, linea = [], [], [], []\n",
    "    lineas = open(\"user_skill\").readlines();\n",
    "    N = len(lineas)\n",
    "    D = len(open(\"skill_id\").readlines());\n",
    "    for n in lineas:\n",
    "        linea = n.split(\":\")\n",
    "        user=int(linea[0])\n",
    "        features = linea[1].split(\"\\n\")[0].split(\",\")\n",
    "        features = map(int, features)\n",
    "        for i in features:\n",
    "            row.append(user)\n",
    "            col.append(i)\n",
    "            data.append(1)\n",
    "    \n",
    "    row = np.array(row)\n",
    "    col = np.array(col)\n",
    "    data = np.array(data)\n",
    "    Z = csr_matrix((data, (row, col)), shape=(N, D))\n",
    "    return Z\n",
    "        \n",
    "Z = CrearSparse()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Se generan las matrices de entrenamiento y de prueba, para ello se utiliza la función \"train_test_split\" de sklearn que divide aleatoriamente los datos según la semilla que se le pase como parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño matriz entrenamiento Z_tr: (5917, 14544)\n",
      "Tamaño matriz pruebas Z_ts: (1973, 14544)\n"
     ]
    }
   ],
   "source": [
    "Z_tr, Z_ts = train_test_split(Z, test_size=0.25, random_state=0)\n",
    "print \"Tamaño matriz entrenamiento Z_tr: \" + str(Z_tr.shape)\n",
    "print \"Tamaño matriz pruebas Z_ts: \" + str(Z_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "competencias = Z.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)  Se crea un gráfico para visualizar el número de usuarios que declara cada competencia. Debido a que son muchas competencias y además están en distintos órdenes de magnitud, se opta por un gráfico logarítmico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bar() takes at least 2 arguments (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-79ad8739c4bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"competencias\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Numero de usuarios\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompetencias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bar() takes at least 2 arguments (0 given)"
     ]
    }
   ],
   "source": [
    "plt.bar(figsize=(12, 8))\n",
    "plt.xlabel(\"competencias\")\n",
    "plt.ylabel(\"Numero de usuarios\")\n",
    "plt.semilogy(competencias.A1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Se escoge en este caso la séptima columna que corresponde a PHP para ser evaluada y estimada por los clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tr = Z_tr.getcol(6).A.T[0]\n",
    "# notar como se escoge indice print y_tr[25,0]\n",
    "X_tr = hstack([Z_tr[:,0:6],Z_tr[:,6+1:]]).tocsr()\n",
    "print \"Dimension matriz de entrenamiento X_tr: \" + str(X_tr.shape)\n",
    "y_ts = Z_ts.getcol(6).A.T[0]\n",
    "X_ts = hstack([Z_ts[:,0:6],Z_ts[:,6+1:]]).tocsr()\n",
    "print \"Dimension matriz de pruebas X_ts: \" + str(X_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e)  A continuación se definen los clasificadores a utilizar, que corresponden a Bernoulli, Multinomial NB, regresión logística, SVM y KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt,yt)\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))\n",
    "    \n",
    "def do_NAIVE_BAYES(x,y,xt,yt,imp=1):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    if imp==1:\n",
    "        score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt,imp=1):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    if imp==1:\n",
    "        score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "def do_LOGIT(x,y,xt,yt,imp=1):\n",
    "    model = LogisticRegression(penalty='l2')\n",
    "    model = model.fit(x, y)\n",
    "    if imp==1:\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "    return model\n",
    "    \n",
    "def do_SVM(x,y,xt,yt,imp=1):\n",
    "    model = LinearSVC()\n",
    "    model = model.fit(x, y)\n",
    "    if imp==1:\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "    return model\n",
    "\n",
    "def do_KNN(x,y,xt,yt,imp=1):\n",
    "    model = KNeighborsClassifier()\n",
    "    model = model.fit(x, y)\n",
    "    if imp==1:\n",
    "        score_the_model(model,x,y,xt,yt,\"K-NN\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_tr =[]\n",
    "acc_ts = []\n",
    "def determinarACC(X_tr,y_tr, X_ts, y_ts, acc_tr, acc_ts, imp=1):\n",
    "    model = do_KNN(X_tr, y_tr, X_ts, y_ts,imp)\n",
    "    acc_tr.append(model.score(X_tr,y_tr))\n",
    "    acc_ts.append(model.score(X_ts,y_ts))\n",
    "    if imp==1:\n",
    "        print '----------------------------------------------------------'\n",
    "    model = do_NAIVE_BAYES(X_tr, y_tr, X_ts, y_ts,imp)\n",
    "    acc_tr.append(model.score(X_tr,y_tr))\n",
    "    acc_ts.append(model.score(X_ts,y_ts))\n",
    "    if imp==1:\n",
    "        print '----------------------------------------------------------'\n",
    "    model = do_MULTINOMIAL(X_tr, y_tr, X_ts, y_ts,imp)\n",
    "    acc_tr.append(model.score(X_tr,y_tr))\n",
    "    acc_ts.append(model.score(X_ts,y_ts))\n",
    "    if imp==1:\n",
    "        print '----------------------------------------------------------'\n",
    "    model = do_LOGIT(X_tr, y_tr, X_ts, y_ts,imp)\n",
    "    acc_tr.append(model.score(X_tr,y_tr))\n",
    "    acc_ts.append(model.score(X_ts,y_ts))\n",
    "    if imp==1:\n",
    "        print '----------------------------------------------------------'\n",
    "    model = do_SVM(X_tr, y_tr, X_ts, y_ts, imp)\n",
    "    acc_tr.append(model.score(X_tr,y_tr))\n",
    "    acc_ts.append(model.score(X_ts,y_ts))\n",
    "    return acc_tr, acc_ts\n",
    "\n",
    "acc_tr, acc_ts = determinarACC(X_tr,y_tr, X_ts, y_ts, acc_tr, acc_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se aprecia en las tablas, el mejor resultado se obtiene mediante regresión logística y SVM, sin embargo estas dos técnicas tienden a sobre ajustar, debido a que se requieren un ajuste de híper-parámetros, ya que al ser un espacio de dimensiones tan grande (14544) los híper-planos que forman separan casi perfectamente el espacio de características en los datos de entrenamiento formando así \"hard margin\". Aun así, siguen siendo técnicas efectivas debido a la naturaleza y simplicidad. Los métodos Naive Bayes generalizan de buena manera y obtienen resultados levemente peores que RL y SVM. \n",
    "\n",
    "Finalmente KNN es uno de los métodos para clasificación más simples, y que en este caso funciona muy bien, a pesar que KNN en un espacio de alta dimensionalidad puede tener un gran error, ya que los puntos que representan los datos están muy dispersos en el espacio, la tarea de agrupar vecinos basado en su cercanía se torna compleja, y si los datos no están muy compactados, se pierde la noción de clases. Afortunadamente este no es el caso, y KNN presenta buenos resultados en términos de complejidad y eficacia.\n",
    "\n",
    "La cantidad de datos es mucho menor que el número de características, por ello la densidad que ocupan los datos en el espacio es muy pequeña, esto muestra cómo afecta la maldición de la dimensionalidad a los algoritmos de clasificación, particularmente a los que se basan en medidas de longitud como la distancia euclidiana al lidiar con problemas de esta naturaleza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotACC(acc_tr, acc_ts):\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "    index = np.arange(5)\n",
    "    bar_width = 0.35\n",
    "\n",
    "    opacity = 0.4\n",
    "    error_config = {'ecolor': '0.3'}\n",
    "\n",
    "    rects1 = plt.bar(index, acc_tr, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     color='b',\n",
    "                     label='train')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, acc_ts, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     color='r',\n",
    "                     label='test')\n",
    "\n",
    "    plt.xlabel('Clasificadores')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Mean accuracy score para distintos clasificadores')\n",
    "    plt.xticks(index + bar_width, ('KNN', 'NB', 'MNB', 'RL', 'SVM'))\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotACC(acc_tr, acc_ts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se observa cómo cambia el comportamiento de SVM al variar el parámetro C que define el margen del híper-plano separador. Una situación similar ocurre con regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LinearSVC(C=0.01)\n",
    "model = model.fit(X_tr, y_tr)\n",
    "score_the_model(model,X_tr,y_tr,X_ts,y_ts,\"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es claro que los algoritmos que permiten una adecuada elección de híper-parámetros tienen mejor desempeño, sobre todo en situaciones de alta dimensionalidad. Con respecto a los métodos Naive Bayes, su desempeño en general es bueno, ya que al tener tantas características de entrada, asumir independencia condicional es factible, y los modelos entregan resultados aceptables. El desacoplamiento de una clase de distribuciones condicionales, significa que cada distribución se puede estimar como una distribución dimensional independiente. Esto ayuda a manejar los problemas derivados de la maldición de la dimensionalidad, ya que no requiere demasiados datos para modelar de buena manera el problema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) En esta seccion se repite el procedimiento anterior, pero variando la cantidad de datos utilizados en el training y testing set. Ademas se evaluan los clasificadores para diferentes competencias del dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "competencias={1:'Team Leadership', 4:'Programming', 5:'Javascript'}\n",
    "for i in [1,4,5]:\n",
    "    fig, ax = plt.subplots(ncols=5,sharey=True, figsize=(25,3))\n",
    "    fig.suptitle('competencia: '+ competencias[i], fontsize=14, fontweight='bold')\n",
    "    fig.subplots_adjust(top=0.75)\n",
    "    #fig.text(0.06, 0.5, 'competencia: '+ competencias[i-1] , ha='center', va='center', rotation='horizontal')\n",
    "    for j,t in zip([0.99,0.95,0.9,0.5,0.1], range(0,5)):\n",
    "        Z_tr, Z_ts = train_test_split(Z, test_size=j, random_state=0)\n",
    "        y_tr = Z_tr.getcol(i).A.T[0]\n",
    "        X_tr = hstack([Z_tr[:,0:i],Z_tr[:,i+1:]]).tocsr()\n",
    "        y_ts = Z_ts.getcol(i).A.T[0]\n",
    "        X_ts = hstack([Z_ts[:,0:i],Z_ts[:,i+1:]]).tocsr()\n",
    "        acc_tr =[]\n",
    "        acc_ts = []\n",
    "        acc_tr, acc_ts = determinarACC(X_tr,y_tr, X_ts, y_ts, acc_tr, acc_ts,imp=0)\n",
    "        \n",
    "        index = np.arange(5)\n",
    "        bar_width = 0.35\n",
    "\n",
    "        opacity = 0.4\n",
    "        error_config = {'ecolor': '0.3'}\n",
    "\n",
    "        rects1 = ax[t].bar(index, acc_tr, bar_width,\n",
    "                         alpha=opacity,\n",
    "                         color='b',\n",
    "                         label='train')\n",
    "\n",
    "        rects2 = ax[t].bar(index + bar_width, acc_ts, bar_width,\n",
    "                         alpha=opacity,\n",
    "                         color='r',\n",
    "                         label='test')\n",
    "        \n",
    "        ax[t].set_title(str((1-j)*100) + '% datos de entrenamiento')\n",
    "        ax[t].set_xticks(index + bar_width)\n",
    "        ax[t].set_xticklabels(['KNN', 'NB', 'MNB', 'RL', 'SVM'])\n",
    "        #ax[t].legend(loc=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, los resultados indican que para cantidades pequeñas de datos de entrenamiento, todas las técnicas presentan una precisión regular y similar sobre el conjunto de pruebas, esto se refleja en las barras rojas para 1% y 5%. Una vez que aumenta la cantidad de datos de entrenamiento, a 10% por ejemplo, los métodos KNN, Naive Bayes y Multinomial Naive Bayes continúan con una precisión similar a las anteriores, en cambio Regresión Logística y SVM a medida que aumentan los datos, entrega mejores resultados sobre el test de prueba, pero tienden a sobre ajustar. \n",
    "\n",
    "Esta es una característica de los métodos discriminativos vs generativos. Los generativos al hacer presunciones más fuertes sobre los datos, por ejemplo que son condicionalmente independientes (clasificador ingenuo), no dependen demasiado de la cantidad de datos, incluso aunque el espacio dimensional es muy grande. Es por esto que son \"eficientes\" y regulares. Regresión logística por su parte, hace menos suposiciones de los datos, por lo mismo es un espacio de alta dimensionalidad requiere muchos datos de entrenamiento para encontrar correlación de las variables. \n",
    "\n",
    "SVM y Regresión logística, al dividir el espacio mediante híper-planos, son técnicas simples que funcionan muy bien en espacios de alta dimensionalidad (muchos features), pero requieren regularización para no sobre ajustar como ocurre en los gráficos anteriores. KNN en este caso presenta buenos resultados, esto puede deberse principalmente a que la clasificación es binaria.  En casos de multiclases KNN en espacios de alta dimensión produce resultados de peor calidad, ya que al utilizar la distancia L2 (euclidiana) al aumentar los features, los puntos del dataset están cada vez más alejados y se necesita un gran conjunto de datos para cubrir más espacio y que la distancia sea más descriptiva.\n",
    "\n",
    "Finalmente, se debe notar que la mayor parte de los gráficos entre \"competencias\" no presentan grandes diferencias, esto puede deberse a que al ser tantas características de entrada, el peso de cada una no afecta en gran medida a los modelos."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
